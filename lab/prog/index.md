# Index

---
[下次更新参考](https://juejin.cn/post/6844904113122050055)

---
目标：加快查找速度

功能：支持单键查询、区间查询、辅助索引、联合索引（既定两列）

---

1、Binary Search Tree

    二叉搜索树由于其极度的单边增长趋势，相当于单向链表。而在单向链表上进行遍历搜索和原本在表中按行搜索没有任何区别，因为从遍历次数上来看还是需要
    遍历相同的次数，而且在删除、插入时还要维护索引。因此使用二叉搜索树来作为索引没有优势只有额外的消耗，因此二叉搜索树不适合作为索引内部的数据结构。

2、Red/Black Tree

    平衡二叉查找树。可以将看做为二叉搜索树的改进版本，其在树的结构失衡非常严重的时候会通过旋转来解决问题。
    
    但是如果数据库中有 2 千万条数据，那么红黑树需要多少层呢？
    树的层级有 25 层，这可是一颗相当高的一棵树，这会极大影响搜索效率。
    
3、哈希索引（单值查询）

    基于哈希表实现，只有精确匹配索引所有列的查询才有效生。对于每一行数据，存储引擎都会对所有的索引列计算一个哈希码(hash code)，哈希码是一个较
    小的值，并且不同键值的行计算出来的哈希码也不一样。哈希索引将所有的哈希码存储在索引中，同时在哈希表中保存指向每个数据行的指针。
    根据哈希值进行寻找对应的地址指针，意味hash槽是有序的，因此查询效率很高；

    限制：
        哈希索引只包含哈希值和行指针，而不存储字段值，所以不能使用索引中的值来避免读取行。
        哈希索引数据并不是按照索引值顺序存储的，所以也就无法用于排序。
        哈希索引不支持部分索引列匹配查找，因为哈希索引始终是使用索引列的全部内容来计算哈希值的。
        哈希索引只支持等值比较查询。
        如果哈希冲突很多的话，一些索引维护操作的代价也会很高。（冲突严重使用链表会增加维护和查询成本）

4、B-tree（非叶子节点存储量小）

    B 树能够将树的高度限制在很大范围内的高度是一个常数级别，即使数据量有千万级别，使树的高度在很大的范围内不随着数据量的增多而增多。
    B 树和平衡二叉树稍有不同的是 B 树属于多叉树又名平衡多路查找树（查找路径不只两个），数据库索引技术里大量使用者 B 树和 B+ 树的数据结构，

    特征：
        排序方式：所有节点关键字是按递增次序排列，并遵循左小右大原则；
        子节点数：非叶节点的子节点数 >1，且 <=M ，且M>=2，空树除外（注：M 阶代表一个树节点最多有多少个查找路径，M=M 路，当 M=2 则是 2 叉树）；
        关键字数：枝节点的关键字数量大于等于 ceil(m/2)-1 个且小于等于 M-1 个；
        所有叶子节点均在同一层、叶子节点除了包含了关键字和关键字记录的指针外也有指向其子节点的指针。

    优势：
        B 树相对于平衡二叉树的不同是，每个节点包含的关键字增多了，特别是在 B 树应用到数据库中的时候，数据库充分利用了磁盘块的原理（磁盘数据存储
        是采用块的形式存储的，每个块的大小为 4K，每次 I/O 进行数据读取时，同一个磁盘块的数据可以一次性读取出来）把节点大小限制和充分使用在磁盘块
        大小范围；把树的节点关键字增多后树的层级比原来的二叉树少了，减少数据查找的次数和复杂度；
        
5、B+tree（mysql常用类型）

    B+ 树是 B 树的一个升级版，相对于 B 树来说 B+ 树更充分的利用了节点的空间，让查询速度更加稳定，其速度完全接近于二分法查找。
    
    特征：
        B+ 树的非叶子节点不保存关键字记录的指针，只进行数据索引(冗余，因为叶子节点上有着完整的索引结构)，这样使得 B+ 树每个非叶子节点所能保存
        的索引值大大增加；
        B+ 树叶子节点保存了父节点的所有关键字记录的指针，所有数据地址必须要到叶子节点才能获取到。所以每次数据查询的次数都一样；
        B+ 树叶子节点的关键字从小到大有序排列，左边结尾数据都会保存右边节点开始数据的指针。
        非叶子节点的子节点数=关键字数

    InnoDB最小的page大小为16k，索引值加地址指针大小为6+8=14B,一个page能存储1170个索引值，存储记录为1k/条，每个page能存储16条，所以
    两层B+Tree 能存储 1170*16 = 18720，三层B+Tree 能存储 1170 * 1170 *16 = 21902400。两千万数据。
    
    具有一下特点：
        B+树的层级更少；
        B+树查询速度更稳定；（数据均在底层叶子节点）
        B+树天然具备排序功能；
        B+树全节点遍历更快；
        B+ 树的范围查找非常方便；（适合区间查询）

6、skip-list（redis内部的有序集合）
        
    更形象的是称为有序链表，无论那种数据结构，如果想要提高查询的效率，势必需要引入顺序性，传统的链表的查询效率低下，通过改进后的跳表，提高了查询速度。
    
    跳表结构：
![](https://spongecaptain.cool/images/img_dataStracture/image-20200804112816024.png)

    跳跃表的 skip 含义就是为了强调虽然其基于链表，但是不同于链表单向的逐个节点比较，而是可以跳跃若干个节点后进行比较（跳跃即逐个的反义词）。

    问题：

    跳跃表和大多数索引数据结构有着一样的问题，在元素删减的时候需要维护索引数据结构，具体来说便是：

    添加新元素节点时，如果索引不同时进行更新，那么索引就会因为没有覆盖大部分元素而降低查找效率；
    删除新元素节点时，如果索引中有对应的节点，如果此时不删除，那么就会引发空指针异常；
    删除节点时通过高层索引向低层索引层层递进，查找，因此时间复杂度在层数最高时为O(logN)，逻辑也比较简单，相当于查询的过程中顺便将节点元素删除了。

    添加节点时逻辑要更复杂一些，因为涉及将哪一个节点选举为高层索引的问题。每一层对于新添加节点的选举逻辑是抛硬币，也就是有 50% 的概率选举为上层链
    表的节点，被选举的节点需要插入到上层链表的相应位置中。然后，又进行抛硬币，判断是否要选举到上上层链表。因此一个新接入的节点即可能没有加入任何索
    引中，也有可能加入到所有索引中。这是一个递归的过程，直到某一次选举失败。

    为什么采用抛硬币的方式？（节点个数少，有时会出现极度糟糕的高度，当节点数趋向大数据时，趋于平稳）

    节点选举是比较困难的，因为跳跃表的节点增删操作不可预测，很难用一种有效的算法确保跳表的索引对于最底层的链表来说是均匀的；
    如果强行追求上层节点个数恰好为下层节点个数的 2 倍，那么
    大数据理论告诉我们，当节点元素足够多时，这种选举策略是趋近于均匀分布的；
    
    总结：
    增加元素：
        新节点和各层索引节点逐一比较，确定原链表的插入位置。O(logN)
        把索引插入到原链表。O(1)
        利用抛硬币的随机方式，决定新节点是否提升为上一级索引。结果为 “正” 则提升并继续抛硬币，结果为 “负” 则停止。O(logN)
    删除元素：
        自上而下，查找第一次出现节点的索引，并逐层找到每一层对应的节点。O(logN)
        删除每一层查找到的节点，如果该层只剩下 1 个节点，删除整个一层（原链表除外）。O(logN)
        总体上，跳跃表删除操作的时间复杂度是 O(logN)。

    跳跃表和二叉搜索树的区别：

        数据结构不同：跳跃表基于链表，二叉搜索树基于树；
        索引的维护效率：跳跃表依靠抛硬币的随机方式维护索引（要求尽量平衡或平均），成本比较低，而平衡二叉搜索树需要基于特定的 reblance 算法重新调整
    树状结构。
        平衡性：跳跃表的平衡性依据随机性来包装，因此最终的查找效率至多趋近于 O(logN)，但是平衡二叉树通过 rebalance 算法，能够达到 O(logN) 的查
    找效率；
        范围查找的复杂性：在做范围查找的时候，平衡树比 skiplist 操作要复杂。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找
    其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在 skiplist 上进行范围查找就非常简单，只需要在找到小值之
    后，对第 1 层链表进行若干步的遍历就可以实现。
        内存占用角度：从内存占用上来说，skiplist 比平衡树更灵活一些。一般来说，平衡树每个节点包含 2 个指针（分别指向左右子树），而 skiplist 
    每个节点包含的指针数目平均为 1/(1-p)，具体取决于参数 p 的大小。如果像 Redis 里的实现一样，取 p=1/4，那么平均每个节点包含 1.33 个指针，
    比平衡树更有优势。
        算法难度：从算法实现难度上来比较，skiplist 比平衡树要简单得多了；
    
    相对于 B+Tree，Skip List 有如下优势：

        B+ Tree 的插入删除操作有可能会引起树结构的变化，需要从新平衡；与之相对的，跳表插入要简单的多，更加简单高效。
        B+ Tree 的实现诸如保持树平衡非常复杂；与之相对的，跳表并没有非常复杂的逻辑，实现相对更加简单。
        取下一个元素可以再常数时间内，相对于 B+ Tree 的对数时间。
        因为链表非常简单，可以很容易的修改跳表结构，以更好地支持诸如范围索引之类的操作。
        链表结构使得多线程修改可以仅用 CAS 保证原子性，从而避免重量级的同步机制。
        链表的持久化更加简单。

7、Adaptive Radix Tree(基于前缀树改进，适用于memory database，Hyper列式数据库实现)

    Radix Tree （基数树)是一种常见的前缀树，Linux Kernel 文件系统就用到了该数据结构：
    
![](https://pic2.zhimg.com/80/v2-f6c00dbbdfc69224f142df9a144e6dbd_720w.jpg)

    每个节点可以存储任意长度的键切片，比如 Linux Kernel 中的基数树每个节点存储 6位的键切片；然而数据库索引很多场景下会被频繁修改，每个节点固定
    长度的键切片会造成时间（切片过长）和空间上（切片过短）的浪费，因此，Hyper 实现了自适应的基数树，也就是节点根据长度的不同分成若干种，随着数据
    的变化而自行调整。

    ART结构：

![](https://pic3.zhimg.com/80/v2-8d60bd39aa71ace3a6ef7e035616e87a_720w.jpg)

    ART 数据节点类型：

![](https://pic3.zhimg.com/80/v2-7c9707ac12f63f2e78a4611a4a794336_720w.jpg)

    其主要特点有：

        树的高度仅取决于键长度。
        更新和删除不涉及到树结构的调整，不需要平衡操作。
        到达叶子节点的路径就是键。
        时间复杂度取决于键的长度，而跟数据量无关，如果数据的增加远远超过键长度的增加，那么使用 ART 将会在性能上带来非常大的收益。
    
    
8、Masstree

    可以理解为B+ Tree 和 Radix Tree 的混合体，即将键切分成多个部分，每个部分为一个节点；每个节点内部又是一个 B+ Tree，兼顾空间和性能。

![](https://nan01ab.github.io/assets/img/masstree-structure.png)

    Masstree将变长键划分成多个固长部分，每个固长部分可以通过int类型表示，而不是char类型。由于处理器处理int类型比较操作的速度远远快于char数组
    的比较，因此Masstree通过int类型的比较进一步加速了查找过程。固定长度可以设置为 CPU 缓存行长度，以增加 CPU 缓存效率。
    
    每个节点是一个 B+ Tree，因此 CPU 在查询的时候可以将节点所代表的B+ Tree 加载到 CPU 缓存中，以增加 CPU 缓存命中率。
    其并发控制用到了Read-Copy-Update(RCU)。读不因任何数据更新而阻塞，但更新数据的时候，需要先复制一份副本，在副本上完成修改，再一次性地替换
    旧数据。因此读不会造成 CPU 缓存无效。

9、Bw-Tree

    paper的目的是为了实现一个高性能的ARSs系统，所谓的ARSs即Atomic Record Stores，提供简单的key-value的原子访问接口，key-value通常提供
    put／get／scan的访问模型。基于ARSs可以很容易实现一个nosql系统，也可以基于它加上事务机制实现传统数据库。

    Bw-Tree主要做了2个优化：

        通过无锁的方式来操作b+tree，提升随机读和范围读的性能。核心的思想是把b+tree的page通过page id（PID）映射map，map的[key, value]变
    成[PID, page value]，把直接对page的修改，变成一个修改的操作记录，加入到“page value”，所以“page value”可能是一个“base page”即page
    原始的内容，和一串对page修改形成的记录的链表，而在修改记录链表中加入一个修改记录节点可以很容易变成一个无锁的方式来实现。另外就是对btree的
    split和merge操作也通过类似的原理，把具体的操作细化成好几个原子操作，避免传统的加锁方式。
        把传统checkpoint刷page的变成通过log struct storage方式刷盘，把随机写变成顺序写，提高写的性能。

10、LSM-Tree(big table提出，levelDB单机版实现，rocksDB改进)

    是一种分层、有序，面相磁盘的数据结构，其核心思想充分利用了，磁盘批量的顺序写要远比随机写性能高出很多围绕这一原理进行设计和优化，以此让性能达
    到最优，正如我们普通的Log的写入方式，这种结构的写入，全部都是以Append的模式追加，不存在删除和修改。不过虽然大量提升了写能力，但是是建立在
    牺牲读性能的基础之上的，适用于多写少读的场景。

    但要想支持更复杂和高效的读取，比如key查询和按range查询，就得需要做一步的设计`，这就是LSM结构，除了利用磁盘顺序写之外，还划分了内存+磁盘多层
    合并结构的原因`。正是基于这种结构再加上不同的优化实现，才造就了在这之上的各种独具特点的NoSQL数据库，如Hbase，Cassandra，Leveldb，
    RocksDB，MongoDB，TiDB等。

    Google的bigtable是一片闭源的高性能的KV系统，而LevelDB就是这个KV系统开源的单机版实现，是高度复刻的版本。
    在LSM-Tree里面，核心的数据结构就是SSTable，全称是Sorted String Table，SSTable的概念其实也是来自于
    Google 的 BigTable 论文.
    
    SST结构：

![](https://spongecaptain.cool/images/img_paper/image-20200725151737956.png)

    Data Block结构：

![](https://spongecaptain.cool/images/img_paper/image-20200725152117064.png)

    Data 结构：

![](https://spongecaptain.cool/images/img_paper/image-20200725152643886.png)

    Entry 结构：

![](https://spongecaptain.cool/images/img_paper/image-20200725153911163.png)

    Filter Block结构：

![](https://spongecaptain.cool/images/img_paper/image-20200725160324741.png)

    Index Block 结构：

![](https://spongecaptain.cool/images/img_paper/image-20200725165041357.png)

    Footer 结构：

![](https://spongecaptain.cool/images/img_paper/image-20200725165126619.png)
    

    B+Tree VS LSM-Tree:
        传统关系型数据采用的底层数据结构是B+树，那么同样是面向磁盘存储的数据结构LSM-Tree相比B+树有什么异同之处呢？
    
        LSM-Tree的设计思路是，将数据拆分为几百M大小的Segments，并是顺序写入。// 一个SSTable是64kb大小
    
        B+Tree则是将数据拆分为固定大小的Block或Page, 一般是4KB大小，（Innodb是默认是16kb大小=4个4k），和磁盘
        一个扇区的大小对应，Page是读写的最小单位。
    
        在数据的更新和删除方面，B+Tree可以做到原地更新和删除，这种方式对数据库事务支持更加友好，因为一个key只会出现
        一个Page页里面，但由于LSM-Tree只能追加写，并且在L0层key的rang会重叠，所以对事务支持较弱，只能在Segment 
        Compaction的时候进行真正地更新和删除。
    
        因此LSM-Tree的优点是支持高吞吐的写（可认为是O（1）），这个特点在分布式系统上更为看重，当然针对读取普通的
        LSM-Tree结构，读取是O（N）的复杂度，在使用索引或者缓存优化后的也可以达到O（logN）的复杂度。
    
        而B+tree的优点是支持高效的读（稳定的OlogN），但是在大规模的写请求下（复杂度O(LogN)），效率会变得比较低，
        因为随着insert的操作，为了维护B+树结构，节点会不断的分裂和合并。操作磁盘的随机读写概率会变大，故导致性能降低。
    
        还有一点需要提到的是基于LSM-Tree分层存储能够做到写的高吞吐，带来的副作用是整个系统必须频繁的进行compaction，
        写入量越大，Compaction的过程越频繁。而compaction是一个compare & merge的过程，非常消耗CPU和存储IO，在高
        吞吐的写入情形下，大量的compaction操作占用大量系统资源，必然带来整个系统性能断崖式下跌，对应用系统产生巨大影响，
        当然我们可以禁用自动Major Compaction，在每天系统低峰期定期触发合并，来避免这个问题。
    
    读性能差：
        读性能，特别是范围读能力性能较差，例如读一条数据首先要看memtable中有没有，然后再扫描1级sstable和2级sstable，则需要多次磁盘io才能读
        到这条数据，特别是1级sstable每个分块的range还可能交叉，需要扫描多个1级sstable文件。另外一个就是在compact的时候会有一个性能的剧烈波动。


-------------------------

## Index的组织形式

1、MyISAM中的B+Tree(其存储文件和索引存储是分开存储的)

    叶节点的data域存放的是数据记录的地址，主索引和辅助索引无任何差别，因为data都是数据地址。

![](https://spongecaptain.cool/images/img_mysql/image-20200710225757162.png)


2、Innodb中的B+tree（集中管理）

    表数据文件本身就是按 B+Tree 组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，
    因此InnoDB表数据文件本身就是主索引。
 
    本身要按主键聚集，所以 InnoDB 要求表必须有主键（MyISAM 可以没有），如果没有显式指定，则 MySQL 系统会自动选择一个可以
    唯一标识数据记录的列作为主键，如果不存在这种列，则 MySQL 自动为 InnoDB 表生成一个隐含字段作为主键，这个字段长度为6个字节，
    类型为长整形。

    对于辅助索引或是非唯一索引，data域存放的都是主键值，需要先通过辅助索引拿到主键值，再通过主键索引取得数据。IO多一轮。

3、NoSQL中的Index

    对于levelDB或是RocksDB或是TiDB等基于Key value实现的数据库，都是去构造指定的索引前缀实现的。
    如：

    Unique Index：m{metadata}_t{tableID}_i{indexID}_Colvalue---rowID，再根据RowID 查找数据

    非 Unique Index：m{metadata}_t{tableID}_i{indexID}_Colvalue_rowID---null，找到主键，查找数据

    对于范围查找而言，都要对所有的key进行判断是否符合where的过滤条件，再拿到主键，获取数据。

4、idea

    一种想法：可能还不成熟。
    主要基于范围查找：对于索引是否可以在nosql的index上再次进行一次封装，TiDB是基于Tikv中的算法实现内部排序保证key有序，
    我们是否可以直接在内存中进行排序，仿照SST的结构做一个索引的索引过滤条件，来加快判定从而加快查找，在传统的B+Tree中是
    保证页内是单链表，页间是双链表，同时每个page中还是保存了主键的最大最小值，是否也可以借鉴。